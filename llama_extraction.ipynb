{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60bb467d-861d-4b07-a48d-8e5aa177c969",
   "metadata": {},
   "source": [
    "# Prompt Engineering Extraction Experiments\n",
    "\n",
    "This benchmark is interesting for a couple of reasons. It's relatively straightforward to saturate by building a model for each field and ensembling, but to have the model output it\n",
    "all in one go is actually a challenge since it involves:\n",
    "\n",
    "1. Following a strict nested JSON schema.\n",
    "2. Understanding the meaning of the nesting and/or the instructions for the API.\n",
    "3. Being able to classify across many classes.\n",
    "\n",
    "OpenAI's function calling endpoints are very good at this. Anthropic's Claude-2 models are OK at this. Many of the other Llama-based models are not excellent at this off-the bat,\n",
    "and make decent trade-offs to get there. \n",
    "\n",
    "This notebook compares 3 open models and then takes a single Llama-v2 based model `llama-v2-34b-code-instruct`, in particular) and applies various prompting strategies to see if they improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47de0d20-d20b-44be-9e41-d2275f0866e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -U --quiet langchain langchain_benchmarks\n",
    "# %pip install -U openai rapidfuzz fireworks-ai anthropic pandas replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75ce4b-f159-4917-9249-01ee88b1b8fc",
   "metadata": {},
   "source": [
    "For this code to work, please configure LangSmith environment variables with your credentials,\n",
    "in addition to your LLM providers' API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c401de19-814e-4bd7-bb9c-7ea6e217985c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "uid = uuid.uuid4().hex[:4]  # Avoid conflicts in project names\n",
    "\n",
    "# Get your API key from https://smith.langchain.com/settings\n",
    "api_keys = [\n",
    "    \"LANGCHAIN_API_KEY\",\n",
    "    \"FIREWORKS_API_KEY\",\n",
    "    \"REPLICATE_API_TOKEN\"\n",
    "]\n",
    "for key in api_keys:\n",
    "    if key not in os.environ:\n",
    "        os.environ[key] = getpass.getpass(f\"Enter your {key}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60f22779-a948-4833-8e8c-ace9ef17f56f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Chat Extraction already exists. Skipping.\n",
      "You can access the dataset at https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>Name       </td><td>Chat Extraction                                                                                                                                            </td></tr>\n",
       "<tr><td>Type       </td><td>ExtractionTask                                                                                                                                             </td></tr>\n",
       "<tr><td>Dataset ID </td><td><a href=\"https://smith.langchain.com/public/00f4444c-9460-4a82-b87a-f50096f1cfef/d\" target=\"_blank\" rel=\"noopener\">00f4444c-9460-4a82-b87a-f50096f1cfef</a></td></tr>\n",
       "<tr><td>Description</td><td>A dataset meant to test the ability of an LLM to extract and infer\n",
       "structured information from a dialogue. The dialogue is between a user and a support\n",
       "engineer. Outputs should be structured as a JSON object and test both the ability\n",
       "of the LLM to correctly structure the information and its ability to perform simple \n",
       "classification tasks.                                                                                                                                                            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ExtractionTask(name='Chat Extraction', dataset_id='https://smith.langchain.com/public/00f4444c-9460-4a82-b87a-f50096f1cfef/d', description='A dataset meant to test the ability of an LLM to extract and infer\\nstructured information from a dialogue. The dialogue is between a user and a support\\nengineer. Outputs should be structured as a JSON object and test both the ability\\nof the LLM to correctly structure the information and its ability to perform simple \\nclassification tasks.', schema=<class 'langchain_benchmarks.extraction.tasks.chat_extraction.schema.GenerateTicket'>, instructions=ChatPromptTemplate(input_variables=['dialogue'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpdesk assistant responsible with extracting information and generating tickets. Dialogues are between a user and a support engineer.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['dialogue'], template='Generate a ticket for the following question-response pair:\\n<Dialogue>\\n{dialogue}\\n</Dialogue>'))]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_benchmarks import clone_public_dataset, registry\n",
    "\n",
    "task = registry[\"Chat Extraction\"]\n",
    "\n",
    "# Clone the dataset to your tenant\n",
    "clone_public_dataset(task.dataset_id, dataset_name=task.name)\n",
    "\n",
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1378a-9a62-477e-bdb8-a7fd10915b62",
   "metadata": {},
   "source": [
    "#### Schema\n",
    "\n",
    "Each extraction task has an expected output schema defined in a Pydantic BaseModel object, which we can use to\n",
    "get a JSON schema object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e302e6-9b3d-42a4-b612-d672c591e8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'GenerateTicket',\n",
       " 'description': 'Generate a ticket containing all the extracted information.',\n",
       " 'type': 'object',\n",
       " 'properties': {'issue_summary': {'title': 'Issue Summary',\n",
       "   'description': 'short (<10 word) summary of the issue or question',\n",
       "   'type': 'string'},\n",
       "  'question': {'title': 'Question',\n",
       "   'description': 'Information inferred from the the question.',\n",
       "   'allOf': [{'$ref': '#/definitions/QuestionCategorization'}]},\n",
       "  'response': {'title': 'Response',\n",
       "   'description': 'Information inferred from the the response.',\n",
       "   'allOf': [{'$ref': '#/definitions/ResponseCategorization'}]}},\n",
       " 'required': ['issue_summary', 'question', 'response'],\n",
       " 'definitions': {'QuestionCategory': {'title': 'QuestionCategory',\n",
       "   'description': 'An enumeration.',\n",
       "   'enum': ['Implementation Issues',\n",
       "    'Feature Requests',\n",
       "    'Concept Explanations',\n",
       "    'Code Optimization',\n",
       "    'Security and Privacy Concerns',\n",
       "    'Model Training and Fine-tuning',\n",
       "    'Data Handling and Manipulation',\n",
       "    'User Interaction Flow',\n",
       "    'Technical Integration',\n",
       "    'Error Handling and Logging',\n",
       "    'Customization and Configuration',\n",
       "    'External API and Data Source Integration',\n",
       "    'Language and Localization',\n",
       "    'Streaming and Real-time Processing',\n",
       "    'Tool Development',\n",
       "    'Function Calling',\n",
       "    'LLM Integrations',\n",
       "    'General Agent Question',\n",
       "    'General Chit Chat',\n",
       "    'Memory',\n",
       "    'Debugging Help',\n",
       "    'Application Design',\n",
       "    'Prompt Templates',\n",
       "    'Cost Tracking',\n",
       "    'Other'],\n",
       "   'type': 'string'},\n",
       "  'Sentiment': {'title': 'Sentiment',\n",
       "   'description': 'An enumeration.',\n",
       "   'enum': ['Negative', 'Neutral', 'Positive'],\n",
       "   'type': 'string'},\n",
       "  'ProgrammingLanguage': {'title': 'ProgrammingLanguage',\n",
       "   'description': 'An enumeration.',\n",
       "   'enum': ['python', 'javascript', 'typescript', 'unknown', 'other'],\n",
       "   'type': 'string'},\n",
       "  'QuestionCategorization': {'title': 'QuestionCategorization',\n",
       "   'type': 'object',\n",
       "   'properties': {'question_category': {'$ref': '#/definitions/QuestionCategory'},\n",
       "    'category_if_other': {'title': 'Category If Other',\n",
       "     'description': \"question category if the category above is 'other'\",\n",
       "     'type': 'string'},\n",
       "    'is_off_topic': {'title': 'Is Off Topic',\n",
       "     'description': 'If the input is general chit chat or does not pertain to technical inqueries about LangChain or building/debugging applications with LLMs/AI, it is off topic. For context, LangChain is a library and framework designed to assist in building applications with LLMs. Questions may also be about similar packages like LangServe, LangSmith, OpenAI, Anthropic, vectorstores, agents, etc.',\n",
       "     'type': 'boolean'},\n",
       "    'toxicity': {'title': 'Toxicity',\n",
       "     'description': 'Whether or not the input question is toxic',\n",
       "     'default': 0,\n",
       "     'exclusiveMaximum': 6,\n",
       "     'minimum': 0,\n",
       "     'type': 'integer'},\n",
       "    'sentiment': {'$ref': '#/definitions/Sentiment'},\n",
       "    'programming_language': {'$ref': '#/definitions/ProgrammingLanguage'}},\n",
       "   'required': ['question_category',\n",
       "    'is_off_topic',\n",
       "    'sentiment',\n",
       "    'programming_language']},\n",
       "  'ResponseType': {'title': 'ResponseType',\n",
       "   'description': 'An enumeration.',\n",
       "   'enum': ['resolve issue',\n",
       "    'provide guidance',\n",
       "    'request information',\n",
       "    'give up',\n",
       "    'none',\n",
       "    'other'],\n",
       "   'type': 'string'},\n",
       "  'ResponseCategorization': {'title': 'ResponseCategorization',\n",
       "   'type': 'object',\n",
       "   'properties': {'response_type': {'$ref': '#/definitions/ResponseType'},\n",
       "    'response_type_if_other': {'title': 'Response Type If Other',\n",
       "     'type': 'string'},\n",
       "    'confidence_level': {'title': 'Confidence Level',\n",
       "     'description': 'The confidence of the assistant in its answer.',\n",
       "     'exclusiveMaximum': 6,\n",
       "     'minimum': 0,\n",
       "     'type': 'integer'},\n",
       "    'followup_actions': {'title': 'Followup Actions',\n",
       "     'description': 'Actions the assistant recommended the user take.',\n",
       "     'type': 'array',\n",
       "     'items': {'type': 'string'}}},\n",
       "   'required': ['response_type', 'confidence_level']}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a64f76-65ae-4367-b43f-f2be3431e7af",
   "metadata": {},
   "source": [
    "Now it's time to measure our chain's effectiveness!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102df41d-2c93-4ffc-a09a-4198ea5b6acc",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "We will experiment with three fairly large open-source model LLMs to see their baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27cc37f1-2dc3-4d8e-a380-3c8296bf105a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': {'issue_summary': 'Square root of 3.14',\n",
       "  'question': {'question_category': 'Mathematics',\n",
       "   'is_off_topic': False,\n",
       "   'toxicity': 0,\n",
       "   'sentiment': 'Neutral',\n",
       "   'programming_language': 'unknown'},\n",
       "  'response': {'response_type': 'give up',\n",
       "   'confidence_level': 5,\n",
       "   'followup_actions': []}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from typing import Dict, Callable, Type, Any, Sequence, Union, Optional\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatFireworks\n",
    "from langchain.output_parsers.json import parse_json_markdown\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.language_models import LanguageModelInput\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, root_validator\n",
    "\n",
    "llama_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a data extraction bot tasked with extracting and inferring information from dialogues and generating tickets. Always respond \"\n",
    "            \"only with json based on the following JSON schema:\\n\\n{schema}\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Generate a ticket from the following question-response pair:\\n\"\n",
    "            \"<Dialogue>\\n{dialogue}\\n</Dialogue>\\n\"\n",
    "            \"Remember, respond directly with this format:\\n\"\n",
    "            '{{\"{function_call}\": ...}}\\n'\n",
    "            \"RESPOND ONLY IN JSON\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = llama_prompt.partial(\n",
    "    schema=task.schema.schema_json(), function_call=task.schema.schema()[\"title\"]\n",
    ")\n",
    "\n",
    "llama_llm = ChatFireworks(\n",
    "    model=\"accounts/fireworks/models/llama-v2-34b-code-instruct\",\n",
    "    model_kwargs={\"max_tokens\": 4000, \"temperature\": 0},\n",
    ")\n",
    "\n",
    "\n",
    "def format_run(dialogue_input: dict):\n",
    "    question = dialogue_input[\"question\"]\n",
    "    answer = dialogue_input[\"answer\"]\n",
    "    return {\n",
    "        \"dialogue\": f\"<question>\\n{question}\\n</question>\\n\"\n",
    "        f\"<assistant-response>\\n{answer}\\n</assistant-response>\"\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_output(ai_message):\n",
    "    content = ai_message.content.strip()\n",
    "    if content.endswith('</s>'):\n",
    "        content = content.replace('</s>', '')\n",
    "    parser = lambda x: json.loads(x, strict=False)\n",
    "    try:\n",
    "        parsed = parse_json_markdown(content, parser=parser)\n",
    "        if \"GenerateTicket\" in parsed:\n",
    "            return {\"output\": parsed[\"GenerateTicket\"]}\n",
    "        return {\"output\": parsed}\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"output\": content}\n",
    "\n",
    "\n",
    "def create_extraction_chain(prompt, llm=llama_llm):\n",
    "    return format_run | prompt | llm | parse_output\n",
    "\n",
    "\n",
    "fireworks_extraction_chain = create_extraction_chain(prompt)\n",
    "fireworks_extraction_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"what's the square root of 3.14?\",\n",
    "        \"answer\": \"not my business.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f4f4b39-d1b0-4f89-aa09-4fe261296dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langsmith.client import Client\n",
    "\n",
    "from langchain_benchmarks.extraction.tasks.chat_extraction import get_eval_config\n",
    "\n",
    "client = Client()\n",
    "\n",
    "eval_config = get_eval_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42d3ffd-8590-4afa-88e0-1bc7838be398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama-v2-34b-code-instruct-bcce-v1' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6/compare?selectedSessions=2bb03041-c9e5-4040-bf4f-81b19e5c2ad4\n",
      "\n",
      "View all tests for Dataset Chat Extraction at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6\n",
      "[------------------------------------------------->] 27/27"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.json_edit_distance</th>\n",
       "      <th>feedback.json_schema</th>\n",
       "      <th>feedback.toxicity_similarity</th>\n",
       "      <th>feedback.sentiment_similarity</th>\n",
       "      <th>feedback.confidence_level_similarity</th>\n",
       "      <th>feedback.question_category</th>\n",
       "      <th>feedback.off_topic_similarity</th>\n",
       "      <th>feedback.programming_language_similarity</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.412327</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.296252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.158415</td>\n",
       "      <td>0.320256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197924</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.266880</td>\n",
       "      <td>0.320256</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.827581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.094092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.434230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.308532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.777280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.387863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.140211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.514832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.427954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.726651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.327288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.json_edit_distance  feedback.json_schema  \\\n",
       "count                     27.000000             27.000000   \n",
       "unique                          NaN                   NaN   \n",
       "top                             NaN                   NaN   \n",
       "freq                            NaN                   NaN   \n",
       "mean                       0.412327              0.888889   \n",
       "std                        0.158415              0.320256   \n",
       "min                        0.094092              0.000000   \n",
       "25%                        0.308532              1.000000   \n",
       "50%                        0.387863              1.000000   \n",
       "75%                        0.514832              1.000000   \n",
       "max                        0.726651              1.000000   \n",
       "\n",
       "        feedback.toxicity_similarity  feedback.sentiment_similarity  \\\n",
       "count                           27.0                      27.000000   \n",
       "unique                           NaN                            NaN   \n",
       "top                              NaN                            NaN   \n",
       "freq                             NaN                            NaN   \n",
       "mean                             1.0                       0.592593   \n",
       "std                              0.0                       0.197924   \n",
       "min                              1.0                       0.500000   \n",
       "25%                              1.0                       0.500000   \n",
       "50%                              1.0                       0.500000   \n",
       "75%                              1.0                       0.500000   \n",
       "max                              1.0                       1.000000   \n",
       "\n",
       "        feedback.confidence_level_similarity  feedback.question_category  \\\n",
       "count                              27.000000                   27.000000   \n",
       "unique                                   NaN                         NaN   \n",
       "top                                      NaN                         NaN   \n",
       "freq                                     NaN                         NaN   \n",
       "mean                                0.933333                    0.074074   \n",
       "std                                 0.200000                    0.266880   \n",
       "min                                 0.000000                    0.000000   \n",
       "25%                                 1.000000                    0.000000   \n",
       "50%                                 1.000000                    0.000000   \n",
       "75%                                 1.000000                    0.000000   \n",
       "max                                 1.000000                    1.000000   \n",
       "\n",
       "        feedback.off_topic_similarity  \\\n",
       "count                       27.000000   \n",
       "unique                            NaN   \n",
       "top                               NaN   \n",
       "freq                              NaN   \n",
       "mean                         0.888889   \n",
       "std                          0.320256   \n",
       "min                          0.000000   \n",
       "25%                          1.000000   \n",
       "50%                          1.000000   \n",
       "75%                          1.000000   \n",
       "max                          1.000000   \n",
       "\n",
       "        feedback.programming_language_similarity error  execution_time  \n",
       "count                                  27.000000     0       27.000000  \n",
       "unique                                       NaN     0             NaN  \n",
       "top                                          NaN   NaN             NaN  \n",
       "freq                                         NaN   NaN             NaN  \n",
       "mean                                    0.444444   NaN        4.296252  \n",
       "std                                     0.506370   NaN        0.827581  \n",
       "min                                     0.000000   NaN        3.434230  \n",
       "25%                                     0.000000   NaN        3.777280  \n",
       "50%                                     0.000000   NaN        4.140211  \n",
       "75%                                     1.000000   NaN        4.427954  \n",
       "max                                     1.000000   NaN        7.327288  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama-v2-70b-chat-28a7-v1' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6/compare?selectedSessions=cd595a34-012c-4df2-849e-a7e2908d4c81\n",
      "\n",
      "View all tests for Dataset Chat Extraction at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6\n",
      "[------------------------------------------------->] 27/27"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.json_edit_distance</th>\n",
       "      <th>feedback.json_schema</th>\n",
       "      <th>feedback.toxicity_similarity</th>\n",
       "      <th>feedback.sentiment_similarity</th>\n",
       "      <th>feedback.confidence_level_similarity</th>\n",
       "      <th>feedback.question_category</th>\n",
       "      <th>feedback.off_topic_similarity</th>\n",
       "      <th>feedback.programming_language_similarity</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.639051</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.222369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.148511</td>\n",
       "      <td>0.192450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465322</td>\n",
       "      <td>0.405236</td>\n",
       "      <td>0.192450</td>\n",
       "      <td>0.465322</td>\n",
       "      <td>0.362014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.403553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.510102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.543340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.452219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.648100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.013310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.744218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.098748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.924549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.787303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.json_edit_distance  feedback.json_schema  \\\n",
       "count                     18.000000             27.000000   \n",
       "unique                          NaN                   NaN   \n",
       "top                             NaN                   NaN   \n",
       "freq                            NaN                   NaN   \n",
       "mean                       0.639051              0.037037   \n",
       "std                        0.148511              0.192450   \n",
       "min                        0.370968              0.000000   \n",
       "25%                        0.543340              0.000000   \n",
       "50%                        0.648100              0.000000   \n",
       "75%                        0.744218              0.000000   \n",
       "max                        0.924549              1.000000   \n",
       "\n",
       "        feedback.toxicity_similarity  feedback.sentiment_similarity  \\\n",
       "count                           27.0                      27.000000   \n",
       "unique                           NaN                            NaN   \n",
       "top                              NaN                            NaN   \n",
       "freq                             NaN                            NaN   \n",
       "mean                             0.0                       0.296296   \n",
       "std                              0.0                       0.465322   \n",
       "min                              0.0                       0.000000   \n",
       "25%                              0.0                       0.000000   \n",
       "50%                              0.0                       0.000000   \n",
       "75%                              0.0                       1.000000   \n",
       "max                              0.0                       1.000000   \n",
       "\n",
       "        feedback.confidence_level_similarity  feedback.question_category  \\\n",
       "count                              27.000000                   27.000000   \n",
       "unique                                   NaN                         NaN   \n",
       "top                                      NaN                         NaN   \n",
       "freq                                     NaN                         NaN   \n",
       "mean                                0.296296                    0.037037   \n",
       "std                                 0.405236                    0.192450   \n",
       "min                                 0.000000                    0.000000   \n",
       "25%                                 0.000000                    0.000000   \n",
       "50%                                 0.000000                    0.000000   \n",
       "75%                                 0.800000                    0.000000   \n",
       "max                                 1.000000                    1.000000   \n",
       "\n",
       "        feedback.off_topic_similarity  \\\n",
       "count                       27.000000   \n",
       "unique                            NaN   \n",
       "top                               NaN   \n",
       "freq                              NaN   \n",
       "mean                         0.296296   \n",
       "std                          0.465322   \n",
       "min                          0.000000   \n",
       "25%                          0.000000   \n",
       "50%                          0.000000   \n",
       "75%                          1.000000   \n",
       "max                          1.000000   \n",
       "\n",
       "        feedback.programming_language_similarity error  execution_time  \n",
       "count                                  27.000000     0       27.000000  \n",
       "unique                                       NaN     0             NaN  \n",
       "top                                          NaN   NaN             NaN  \n",
       "freq                                         NaN   NaN             NaN  \n",
       "mean                                    0.148148   NaN        6.222369  \n",
       "std                                     0.362014   NaN        3.403553  \n",
       "min                                     0.000000   NaN        3.510102  \n",
       "25%                                     0.000000   NaN        4.452219  \n",
       "50%                                     0.000000   NaN        5.013310  \n",
       "75%                                     0.000000   NaN        7.098748  \n",
       "max                                     1.000000   NaN       19.787303  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'yi-34b-200k-capybara-9ac9-v1' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6/compare?selectedSessions=07ea7e7c-3743-4b51-af75-9194dc8a7205\n",
      "\n",
      "View all tests for Dataset Chat Extraction at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6\n",
      "[------------------------------------------------->] 27/27"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.json_edit_distance</th>\n",
       "      <th>feedback.json_schema</th>\n",
       "      <th>feedback.toxicity_similarity</th>\n",
       "      <th>feedback.sentiment_similarity</th>\n",
       "      <th>feedback.confidence_level_similarity</th>\n",
       "      <th>feedback.question_category</th>\n",
       "      <th>feedback.off_topic_similarity</th>\n",
       "      <th>feedback.programming_language_similarity</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.927253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.409956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.279934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.616294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.823253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.138749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.988713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feedback.json_edit_distance  feedback.json_schema  \\\n",
       "count                            0                  27.0   \n",
       "unique                           0                   NaN   \n",
       "top                            NaN                   NaN   \n",
       "freq                           NaN                   NaN   \n",
       "mean                           NaN                   0.0   \n",
       "std                            NaN                   0.0   \n",
       "min                            NaN                   0.0   \n",
       "25%                            NaN                   0.0   \n",
       "50%                            NaN                   0.0   \n",
       "75%                            NaN                   0.0   \n",
       "max                            NaN                   0.0   \n",
       "\n",
       "        feedback.toxicity_similarity  feedback.sentiment_similarity  \\\n",
       "count                           27.0                           27.0   \n",
       "unique                           NaN                            NaN   \n",
       "top                              NaN                            NaN   \n",
       "freq                             NaN                            NaN   \n",
       "mean                             0.0                            0.0   \n",
       "std                              0.0                            0.0   \n",
       "min                              0.0                            0.0   \n",
       "25%                              0.0                            0.0   \n",
       "50%                              0.0                            0.0   \n",
       "75%                              0.0                            0.0   \n",
       "max                              0.0                            0.0   \n",
       "\n",
       "        feedback.confidence_level_similarity  feedback.question_category  \\\n",
       "count                                   27.0                        27.0   \n",
       "unique                                   NaN                         NaN   \n",
       "top                                      NaN                         NaN   \n",
       "freq                                     NaN                         NaN   \n",
       "mean                                     0.0                         0.0   \n",
       "std                                      0.0                         0.0   \n",
       "min                                      0.0                         0.0   \n",
       "25%                                      0.0                         0.0   \n",
       "50%                                      0.0                         0.0   \n",
       "75%                                      0.0                         0.0   \n",
       "max                                      0.0                         0.0   \n",
       "\n",
       "        feedback.off_topic_similarity  \\\n",
       "count                            27.0   \n",
       "unique                            NaN   \n",
       "top                               NaN   \n",
       "freq                              NaN   \n",
       "mean                              0.0   \n",
       "std                               0.0   \n",
       "min                               0.0   \n",
       "25%                               0.0   \n",
       "50%                               0.0   \n",
       "75%                               0.0   \n",
       "max                               0.0   \n",
       "\n",
       "        feedback.programming_language_similarity error  execution_time  \n",
       "count                                       27.0     0       27.000000  \n",
       "unique                                       NaN     0             NaN  \n",
       "top                                          NaN   NaN             NaN  \n",
       "freq                                         NaN   NaN             NaN  \n",
       "mean                                         0.0   NaN        3.927253  \n",
       "std                                          0.0   NaN        0.409956  \n",
       "min                                          0.0   NaN        3.279934  \n",
       "25%                                          0.0   NaN        3.616294  \n",
       "50%                                          0.0   NaN        3.823253  \n",
       "75%                                          0.0   NaN        4.138749  \n",
       "max                                          0.0   NaN        4.988713  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_to_try = [\n",
    "    \"llama-v2-34b-code-instruct\",\n",
    "    \"llama-v2-70b-chat\",\n",
    "    \"yi-34b-200k-capybara\",\n",
    "]\n",
    "\n",
    "\n",
    "fireworks_extraction_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"what's the square root of 3.14?\",\n",
    "        \"answer\": \"not my business.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "test_runs = {}\n",
    "for model_name in models_to_try:\n",
    "    llm = ChatFireworks(\n",
    "        model=f\"accounts/fireworks/models/{model_name}\",\n",
    "        model_kwargs={\"max_tokens\": 4000, \"temperature\": 0},\n",
    "    )\n",
    "    fireworks_extraction_chain = create_extraction_chain(prompt, llm=llm)\n",
    "    test_runs[model_name] = client.run_on_dataset(\n",
    "        dataset_name=task.name,\n",
    "        llm_or_chain_factory=fireworks_extraction_chain,\n",
    "        evaluation=eval_config,\n",
    "        verbose=True,\n",
    "        project_name=f\"{model_name}-{uuid.uuid4().hex[:4]}-v1\",\n",
    "        project_metadata={\"arch\": \"base\", \"model\": model_name},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4892b0-906c-455d-81c5-fcb854b09775",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Reviewing the tables above, we can see that the naive applications of Llama-v2-70B-chat\n",
    "and Yi-34B aren't generating json schema in the way we'd like.\n",
    "\n",
    "Even for the 'best performing' model, `llama-v2-34b-code-instruct`, there are some fairly big problems here:\n",
    "\n",
    "1. Json schema isn't always honored.\n",
    "2. Sentiment prediction is surprisingly poor\n",
    "3. Programming language similarity is bad.\n",
    "4. Question category is bad (this is less surprising)\n",
    "\n",
    "\n",
    "Let's review some of the specific outputs to see more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8e29a06-fffa-4b4f-b6fe-1dc8762a1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_v2_test_run = test_runs[\"llama-v2-34b-code-instruct\"]\n",
    "df = llama_v2_test_run.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba0b267c-d729-434a-b1d2-7c9740dba4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ValidationError(model=\\'GenerateTicket\\', errors=[{\\'loc\\': (\\'question\\', \\'question_category\\'), \\'msg\\': \"value is not a valid enumeration member; permitted: \\'Implementation Issues\\', \\'Feature Requests\\', \\'Concept Explanations\\', \\'Code Optimization\\', \\'Security and Privacy Concerns\\', \\'Mo\n"
     ]
    }
   ],
   "source": [
    "run_ids = list(client.list_runs(project_name=llama_v2_test_run[\"project_name\"]))\n",
    "feedback = list(\n",
    "    client.list_feedback(run_ids=[r.id for r in run_ids], feedback_key=\"json_schema\")\n",
    ")\n",
    "# [f.comment for f in feedback if f.score == 0]\n",
    "# Shows the question_category is typically the value that's mistaken (enum)\n",
    "print(str([f.comment for f in feedback if f.score == 0])[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981f7969-9935-4b27-bb8d-a7bb91687dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.sentiment\n",
      "Positive    22\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>reference.sentiment</th>\n",
       "      <th>outputs.sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23a81130-2ad9-46cf-ad27-46589bcea94a</th>\n",
       "      <td>je travail sur python. je souhaite joindre ces...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1a1a2e8-6f4c-4325-8aaa-ea20e2449268</th>\n",
       "      <td>how do I run llama2 using pandas</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140a4819-0046-469d-b4df-8e747ddae112</th>\n",
       "      <td>if Im useing ConversationalRetrievalChain how ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b0a9dd9-68ce-41a1-9f9d-067d93175477</th>\n",
       "      <td>I want to create an app which:\\n- chats with u...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54ca82f6-30c4-4ce1-9c3b-4177caf11906</th>\n",
       "      <td>OpenAIWhisperParser</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        inputs.question  \\\n",
       "23a81130-2ad9-46cf-ad27-46589bcea94a  je travail sur python. je souhaite joindre ces...   \n",
       "d1a1a2e8-6f4c-4325-8aaa-ea20e2449268                   how do I run llama2 using pandas   \n",
       "140a4819-0046-469d-b4df-8e747ddae112  if Im useing ConversationalRetrievalChain how ...   \n",
       "7b0a9dd9-68ce-41a1-9f9d-067d93175477  I want to create an app which:\\n- chats with u...   \n",
       "54ca82f6-30c4-4ce1-9c3b-4177caf11906                                OpenAIWhisperParser   \n",
       "\n",
       "                                     reference.sentiment outputs.sentiment  \n",
       "23a81130-2ad9-46cf-ad27-46589bcea94a             Neutral          Positive  \n",
       "d1a1a2e8-6f4c-4325-8aaa-ea20e2449268             Neutral          Positive  \n",
       "140a4819-0046-469d-b4df-8e747ddae112             Neutral          Positive  \n",
       "7b0a9dd9-68ce-41a1-9f9d-067d93175477             Neutral          Positive  \n",
       "54ca82f6-30c4-4ce1-9c3b-4177caf11906             Neutral          Positive  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_flattened_df(df, metric_key, key, which=\"question\"):\n",
    "    new_df = df[df[f\"feedback.{metric_key}\"] < 1].copy()\n",
    "    new_df[f\"reference.{key}\"] = new_df[\"reference.output\"].apply(\n",
    "        lambda x: x[which].get(key)\n",
    "    )\n",
    "    new_df[f\"outputs.{key}\"] = new_df[\"outputs.output\"].apply(\n",
    "        lambda x: x[which].get(key)\n",
    "    )\n",
    "    return new_df[[f\"inputs.{which}\", f\"reference.{key}\", f\"outputs.{key}\"]]\n",
    "\n",
    "\n",
    "sentiment_failed = get_flattened_df(df, \"sentiment_similarity\", \"sentiment\")\n",
    "print(sentiment_failed[\"outputs.sentiment\"].value_counts())\n",
    "\n",
    "# It looks like the model is getting confused by the sentiment\n",
    "# of the question vs. the answer\n",
    "sentiment_failed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f16289-e799-4e2c-8725-9ef9f05c84e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.programming_language\n",
      "python    15\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>reference.programming_language</th>\n",
       "      <th>outputs.programming_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140a4819-0046-469d-b4df-8e747ddae112</th>\n",
       "      <td>if Im useing ConversationalRetrievalChain how ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b0a9dd9-68ce-41a1-9f9d-067d93175477</th>\n",
       "      <td>I want to create an app which:\\n- chats with u...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55e7b4b6-d64d-4fd1-b769-efbb1794fc82</th>\n",
       "      <td>show me an example of a prompt template return...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17a8dfde-49aa-4772-bc54-65d7e691eec1</th>\n",
       "      <td>Is it possible to use function call with llama...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07c3ee79-be73-44f4-b229-cd98ca04e320</th>\n",
       "      <td>i am using openai functions to get the output ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        inputs.question  \\\n",
       "140a4819-0046-469d-b4df-8e747ddae112  if Im useing ConversationalRetrievalChain how ...   \n",
       "7b0a9dd9-68ce-41a1-9f9d-067d93175477  I want to create an app which:\\n- chats with u...   \n",
       "55e7b4b6-d64d-4fd1-b769-efbb1794fc82  show me an example of a prompt template return...   \n",
       "17a8dfde-49aa-4772-bc54-65d7e691eec1  Is it possible to use function call with llama...   \n",
       "07c3ee79-be73-44f4-b229-cd98ca04e320  i am using openai functions to get the output ...   \n",
       "\n",
       "                                     reference.programming_language  \\\n",
       "140a4819-0046-469d-b4df-8e747ddae112                        unknown   \n",
       "7b0a9dd9-68ce-41a1-9f9d-067d93175477                        unknown   \n",
       "55e7b4b6-d64d-4fd1-b769-efbb1794fc82                        unknown   \n",
       "17a8dfde-49aa-4772-bc54-65d7e691eec1                        unknown   \n",
       "07c3ee79-be73-44f4-b229-cd98ca04e320                        unknown   \n",
       "\n",
       "                                     outputs.programming_language  \n",
       "140a4819-0046-469d-b4df-8e747ddae112                       python  \n",
       "7b0a9dd9-68ce-41a1-9f9d-067d93175477                       python  \n",
       "55e7b4b6-d64d-4fd1-b769-efbb1794fc82                       python  \n",
       "17a8dfde-49aa-4772-bc54-65d7e691eec1                       python  \n",
       "07c3ee79-be73-44f4-b229-cd98ca04e320                       python  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_failed = get_flattened_df(\n",
    "    df, \"programming_language_similarity\", \"programming_language\"\n",
    ")\n",
    "print(pl_failed[\"outputs.programming_language\"].value_counts())\n",
    "\n",
    "# It looks like the same thing is happening here: it's leaning on the response\n",
    "pl_failed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb461fb-afa1-4836-85d8-a258b6ec1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.question_category\n",
      "Technical Integration    17\n",
      "Implementation Issues     3\n",
      "Tool Development          2\n",
      "Technical Inquiry         2\n",
      "Development               1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>reference.question_category</th>\n",
       "      <th>outputs.question_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23a81130-2ad9-46cf-ad27-46589bcea94a</th>\n",
       "      <td>je travail sur python. je souhaite joindre ces...</td>\n",
       "      <td>Data Handling and Manipulation</td>\n",
       "      <td>Technical Integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1a1a2e8-6f4c-4325-8aaa-ea20e2449268</th>\n",
       "      <td>how do I run llama2 using pandas</td>\n",
       "      <td>LLM Integrations</td>\n",
       "      <td>Technical Integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140a4819-0046-469d-b4df-8e747ddae112</th>\n",
       "      <td>if Im useing ConversationalRetrievalChain how ...</td>\n",
       "      <td>Memory</td>\n",
       "      <td>Technical Integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7b0a9dd9-68ce-41a1-9f9d-067d93175477</th>\n",
       "      <td>I want to create an app which:\\n- chats with u...</td>\n",
       "      <td>Application Design</td>\n",
       "      <td>Tool Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54ca82f6-30c4-4ce1-9c3b-4177caf11906</th>\n",
       "      <td>OpenAIWhisperParser</td>\n",
       "      <td>Concept Explanations</td>\n",
       "      <td>Technical Integration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        inputs.question  \\\n",
       "23a81130-2ad9-46cf-ad27-46589bcea94a  je travail sur python. je souhaite joindre ces...   \n",
       "d1a1a2e8-6f4c-4325-8aaa-ea20e2449268                   how do I run llama2 using pandas   \n",
       "140a4819-0046-469d-b4df-8e747ddae112  if Im useing ConversationalRetrievalChain how ...   \n",
       "7b0a9dd9-68ce-41a1-9f9d-067d93175477  I want to create an app which:\\n- chats with u...   \n",
       "54ca82f6-30c4-4ce1-9c3b-4177caf11906                                OpenAIWhisperParser   \n",
       "\n",
       "                                         reference.question_category  \\\n",
       "23a81130-2ad9-46cf-ad27-46589bcea94a  Data Handling and Manipulation   \n",
       "d1a1a2e8-6f4c-4325-8aaa-ea20e2449268                LLM Integrations   \n",
       "140a4819-0046-469d-b4df-8e747ddae112                          Memory   \n",
       "7b0a9dd9-68ce-41a1-9f9d-067d93175477              Application Design   \n",
       "54ca82f6-30c4-4ce1-9c3b-4177caf11906            Concept Explanations   \n",
       "\n",
       "                                     outputs.question_category  \n",
       "23a81130-2ad9-46cf-ad27-46589bcea94a     Technical Integration  \n",
       "d1a1a2e8-6f4c-4325-8aaa-ea20e2449268     Technical Integration  \n",
       "140a4819-0046-469d-b4df-8e747ddae112     Technical Integration  \n",
       "7b0a9dd9-68ce-41a1-9f9d-067d93175477          Tool Development  \n",
       "54ca82f6-30c4-4ce1-9c3b-4177caf11906     Technical Integration  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc_failed = get_flattened_df(df, \"question_category\", \"question_category\")\n",
    "print(qc_failed[\"outputs.question_category\"].value_counts())\n",
    "\n",
    "# It looks like it really wants to guess Technical Integration\n",
    "qc_failed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b2ff00-36bc-4ebb-b98d-6a44a71725e6",
   "metadata": {},
   "source": [
    "## Round 2: Be Explicit\n",
    "\n",
    "Lets try to prompt engineer an improvement. We need it to respect enum values (not invent new ones). We also need each question/response value to only consider the question or response. Finally, we remind the bot what off-topic means in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb4bb40-7382-400f-ad1b-245c15b50306",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message_tuple = (\n",
    "    \"user\",\n",
    "    \"Consider the following:\\n<Dialogue>\\n{dialogue}\\n</Dialogue>\\n\\n\"\n",
    "    \"Generate a ticket based on the preceding dialogue.\"\n",
    "    \" Any values in the question/response sections of the body must\"\n",
    "    \" only be based on content from the question or response, respectively.\"\n",
    "    \" For instance, the values for question sentiment and question programming language\"\n",
    "    \" should ignore the response content - even if the response contains code, that\"\n",
    "    \" doesn't mean the question programming language is that code language.\"\n",
    "    \" Strictly adhere to all enums in the API's schema. Select the best\"\n",
    "    \" question_category from the list provided - don't just pick a generic one.\"\n",
    "    \" Respond directly in JSON, like:\\n\"\n",
    "    '{{\"{function_call}\": ...}}',\n",
    ")\n",
    "llama_prompt_2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a data extraction bot tasked with extracting and\"\n",
    "            \" inferring information from dialogues. You must submit tickets\"\n",
    "            \" through a strict API with the following JSON schema:\\n\\n\"\n",
    "            \"{schema}\",\n",
    "        ),\n",
    "        user_message_tuple,\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_2 = llama_prompt_2.partial(\n",
    "    schema=task.schema.schema_json(), function_call=task.schema.schema()[\"title\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ba09ca38-cb96-4f95-b825-c70c0fe573df",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "fireworks_extraction_chain_2 = create_extraction_chain(prompt_2)\n",
    "\n",
    "llama_v2_test_run = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=fireworks_extraction_chain_2,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    project_name=f\"llama-v2-34b-code-instruct-{uuid.uuid4().hex[:4]}-v1\",\n",
    "    project_metadata={\n",
    "        \"arch\": \"more-instructions\",\n",
    "        \"model\": \"llama-v2-34b-code-instruct\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48a32f-dc14-4c66-a932-3ae7ffaf8092",
   "metadata": {},
   "source": [
    "The results really haven't improved. Sentiment went down, and while programming language and question category did improve, the difference is not dramatic.\n",
    "\n",
    "Maybe some few-shot prompting will help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d89e9ae-3fea-4405-ba04-d2f0e9d3b34a",
   "metadata": {},
   "source": [
    "## Round 3: Few-Shot Prompting\n",
    "\n",
    "We will give it 3 examples as better cueues for the types of responses we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aea2001-75ac-4daf-92da-4ce129e72be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'GenerateTicket': {'issue_summary': 'Assistant responded with toxic sentiment',\n",
       "   'question': {'question_category': 'General Chit Chat',\n",
       "    'is_off_topic': True,\n",
       "    'toxicity': 6,\n",
       "    'sentiment': 'Negative',\n",
       "    'programming_language': 'unknown'},\n",
       "   'response': {'response_type': 'none',\n",
       "    'confidence_level': 0,\n",
       "    'followup_actions': []}}},\n",
       " {'GenerateTicket': {'issue_summary': 'How to use Llama 2 locally?',\n",
       "   'question': {'question_category': 'Technical Integration',\n",
       "    'is_off_topic': False,\n",
       "    'toxicity': 0,\n",
       "    'sentiment': 'Positive',\n",
       "    'programming_language': 'python'},\n",
       "   'response': {'response_type': 'provide guidance',\n",
       "    'confidence_level': 5,\n",
       "    'followup_actions': ['Use Llama.cpp and call in python']}}},\n",
       " {'GenerateTicket': {'issue_summary': 'Debugging ImportError: langchain.superbase not found',\n",
       "   'question': {'question_category': 'Debugging Help',\n",
       "    'is_off_topic': False,\n",
       "    'toxicity': 0,\n",
       "    'sentiment': 'Negative',\n",
       "    'programming_language': 'python'},\n",
       "   'response': {'response_type': 'provide guidance',\n",
       "    'confidence_level': 5,\n",
       "    'followup_actions': ['Check the documentation for the correct import path']}}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_examples = [\n",
    "    {\n",
    "        \"question\": \"how are you doing?\",\n",
    "        # Negative example to show that sentiment should only come from the question\n",
    "        \"answer\": \"I hate you\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Llms are exciting. How do I Llama 2 locally?\",\n",
    "        # Same\n",
    "        \"answer\": \"You can use Llama.cpp and call in python\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I'm so frustrated with the docs. How do I debug this issue 'ImportError: langchain.superbase not found'\",\n",
    "        # Same\n",
    "        \"answer\": \"It seems like you're trying to import a path that isn't actually found in the docs!\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Map back to the right output\n",
    "generation_chain = fireworks_extraction_chain_2 | (\n",
    "    lambda x: {task.schema.schema()[\"title\"]: x.get(\"output\")}\n",
    ")\n",
    "\n",
    "predicted = generation_chain.batch(dialogue_examples)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aae2cf9-94c4-4e45-a039-ced05f0a8383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will fix up the answers\n",
    "\n",
    "expected_answers = [\n",
    "    {\n",
    "        \"GenerateTicket\": {\n",
    "            \"issue_summary\": \"Greeting\",\n",
    "            \"question\": {\n",
    "                \"question_category\": \"General Chit Chat\",\n",
    "                \"is_off_topic\": True,\n",
    "                \"toxicity\": 0,\n",
    "                \"sentiment\": \"Neutral\",\n",
    "                \"programming_language\": \"none\",\n",
    "            },\n",
    "            \"response\": {\n",
    "                \"response_type\": \"none\",\n",
    "                \"confidence_level\": 5,\n",
    "                \"followup_actions\": [],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"GenerateTicket\": {\n",
    "            \"issue_summary\": \"How to run Llama 2 locally?\",\n",
    "            \"question\": {\n",
    "                \"question_category\": \"LLM Integrations\",\n",
    "                \"is_off_topic\": False,\n",
    "                \"toxicity\": 0,\n",
    "                \"sentiment\": \"Positive\",\n",
    "                \"programming_language\": \"unknown\",\n",
    "            },\n",
    "            \"response\": {\n",
    "                \"response_type\": \"provide guidance\",\n",
    "                \"confidence_level\": 5,\n",
    "                \"followup_actions\": [\"Use Llama.cpp\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"GenerateTicket\": {\n",
    "            \"issue_summary\": \"ImportError: langchain.superbase not found\",\n",
    "            \"question\": {\n",
    "                \"question_category\": \"Debugging Help\",\n",
    "                \"is_off_topic\": False,\n",
    "                \"toxicity\": 0,\n",
    "                \"sentiment\": \"Negative\",\n",
    "                \"programming_language\": \"python\",\n",
    "            },\n",
    "            \"response\": {\n",
    "                \"response_type\": \"provide guidance\",\n",
    "                \"confidence_level\": 3,\n",
    "                \"followup_actions\": [\n",
    "                    \"Check the documentation for the correct import path\"\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# Format the examples as desired\n",
    "examples = [\n",
    "    {**format_run(ex), \"output\": json.dumps(ans)}\n",
    "    for ex, ans in zip(dialogue_examples, expected_answers)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eea23c38-63e6-4c6a-9b33-5745bfd545b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "# This is a prompt template used to format each individual example.\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        user_message_tuple,\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ").partial(function_call=task.schema.schema()[\"title\"])\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "llama_prompt_3 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a data extraction bot tasked with extracting and\"\n",
    "            \" inferring information from dialogues. You must submit tickets\"\n",
    "            \" through a strict API with the following JSON schema:\\n\\n\"\n",
    "            \"{schema}\",\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        user_message_tuple,\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_3 = llama_prompt_3.partial(\n",
    "    schema=task.schema.schema_json(), function_call=task.schema.schema()[\"title\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9795f95b-2298-45ad-87f7-734c7308707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': {'issue_summary': 'How to do hybrid search',\n",
       "  'question': {'question_category': 'Search',\n",
       "   'is_off_topic': False,\n",
       "   'toxicity': 0,\n",
       "   'sentiment': 'Neutral',\n",
       "   'programming_language': 'python'},\n",
       "  'response': {'response_type': 'provide guidance',\n",
       "   'confidence_level': 3,\n",
       "   'followup_actions': ['Use a compatible LangChain vectorstore and add a filter parameter']}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireworks_extraction_chain_3 = create_extraction_chain(prompt_3)\n",
    "\n",
    "fireworks_extraction_chain_3.invoke(\n",
    "    {\n",
    "        \"question\": \"How do I do hybrid search?\",\n",
    "        \"answer\": \"You can one of the compatible LangChain vectorstores \"\n",
    "        \"(from langchain.vectorstores import ...) and add a filter parameter.\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d93122c-0d03-4639-9008-2f1375fcc3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama-v2-34b-code-instruct-34b8-v2' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6/compare?selectedSessions=379cfcd2-ddc1-4866-9d41-9d59733ddfc1\n",
      "\n",
      "View all tests for Dataset Chat Extraction at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6\n",
      "[------------------------------------------------->] 27/27"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.json_edit_distance</th>\n",
       "      <th>feedback.json_schema</th>\n",
       "      <th>feedback.toxicity_similarity</th>\n",
       "      <th>feedback.sentiment_similarity</th>\n",
       "      <th>feedback.confidence_level_similarity</th>\n",
       "      <th>feedback.question_category</th>\n",
       "      <th>feedback.off_topic_similarity</th>\n",
       "      <th>feedback.programming_language_similarity</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.395439</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.414929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.174859</td>\n",
       "      <td>0.500712</td>\n",
       "      <td>0.192450</td>\n",
       "      <td>0.270854</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>0.266880</td>\n",
       "      <td>0.362014</td>\n",
       "      <td>0.480384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.759025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.852376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.290873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.184088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.344498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.959597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.525474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.463420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.904085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.600379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.json_edit_distance  feedback.json_schema  \\\n",
       "count                     26.000000             27.000000   \n",
       "unique                          NaN                   NaN   \n",
       "top                             NaN                   NaN   \n",
       "freq                            NaN                   NaN   \n",
       "mean                       0.395439              0.592593   \n",
       "std                        0.174859              0.500712   \n",
       "min                        0.087146              0.000000   \n",
       "25%                        0.290873              0.000000   \n",
       "50%                        0.344498              1.000000   \n",
       "75%                        0.525474              1.000000   \n",
       "max                        0.904085              1.000000   \n",
       "\n",
       "        feedback.toxicity_similarity  feedback.sentiment_similarity  \\\n",
       "count                      27.000000                      27.000000   \n",
       "unique                           NaN                            NaN   \n",
       "top                              NaN                            NaN   \n",
       "freq                             NaN                            NaN   \n",
       "mean                        0.962963                       0.851852   \n",
       "std                         0.192450                       0.270854   \n",
       "min                         0.000000                       0.000000   \n",
       "25%                         1.000000                       0.750000   \n",
       "50%                         1.000000                       1.000000   \n",
       "75%                         1.000000                       1.000000   \n",
       "max                         1.000000                       1.000000   \n",
       "\n",
       "        feedback.confidence_level_similarity  feedback.question_category  \\\n",
       "count                              27.000000                   27.000000   \n",
       "unique                                   NaN                         NaN   \n",
       "top                                      NaN                         NaN   \n",
       "freq                                     NaN                         NaN   \n",
       "mean                                0.888889                    0.074074   \n",
       "std                                 0.224179                    0.266880   \n",
       "min                                 0.000000                    0.000000   \n",
       "25%                                 0.800000                    0.000000   \n",
       "50%                                 1.000000                    0.000000   \n",
       "75%                                 1.000000                    0.000000   \n",
       "max                                 1.000000                    1.000000   \n",
       "\n",
       "        feedback.off_topic_similarity  \\\n",
       "count                       27.000000   \n",
       "unique                            NaN   \n",
       "top                               NaN   \n",
       "freq                              NaN   \n",
       "mean                         0.851852   \n",
       "std                          0.362014   \n",
       "min                          0.000000   \n",
       "25%                          1.000000   \n",
       "50%                          1.000000   \n",
       "75%                          1.000000   \n",
       "max                          1.000000   \n",
       "\n",
       "        feedback.programming_language_similarity error  execution_time  \n",
       "count                                  27.000000     0       27.000000  \n",
       "unique                                       NaN     0             NaN  \n",
       "top                                          NaN   NaN             NaN  \n",
       "freq                                         NaN   NaN             NaN  \n",
       "mean                                    0.333333   NaN        4.414929  \n",
       "std                                     0.480384   NaN        2.759025  \n",
       "min                                     0.000000   NaN        2.852376  \n",
       "25%                                     0.000000   NaN        3.184088  \n",
       "50%                                     0.000000   NaN        3.959597  \n",
       "75%                                     1.000000   NaN        4.463420  \n",
       "max                                     1.000000   NaN       17.600379  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_v2_few_shot_test_run = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=fireworks_extraction_chain_3,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    project_name=f\"llama-v2-34b-code-instruct-{uuid.uuid4().hex[:4]}-v2\",\n",
    "    project_metadata={\"arch\": \"3-shot\", \"model\": \"llama-v2-34b-code-instruct\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8397641-f9bd-4fa7-aff9-a3d9e2fe51cb",
   "metadata": {},
   "source": [
    "The only thing that improved was the sentiment score, which really is not impressive, given that the test set is completely imbalanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008f34b-915e-41f7-b6a2-35a41bbef496",
   "metadata": {},
   "source": [
    "## Round 4: CoT\n",
    "\n",
    "Let's take a step back and ask the model to do so as well, via CoT prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02d99b1e-981b-418e-bad2-a9246cbf3be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateTicket(issue_summary='How to do hybrid search', question=QuestionCategorization(question_category=<QuestionCategory.TECHNICAL_INTEGRATION: 'Technical Integration'>, category_if_other=None, is_off_topic=False, toxicity=0, sentiment=<Sentiment.POSITIVE: 'Positive'>, programming_language=<ProgrammingLanguage.PYTHON: 'python'>), response=ResponseCategorization(response_type=<ResponseType.PROVIDE_GUIDANCE: 'provide guidance'>, response_type_if_other=None, confidence_level=5, followup_actions=['Use a compatible LangChain vectorstore', 'Add a filter parameter']))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_prompt_4 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a data extraction bot tasked with extracting and\"\n",
    "            \" inferring information from dialogues. You must submit tickets\"\n",
    "            \" through a strict API with the following JSON schema:\\n\\n\"\n",
    "            \"{schema}\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Consider the following:\\n<Dialogue>\\n{dialogue}\\n</Dialogue>\\n\\n\"\n",
    "            \"Generate a ticket based on the preceding dialogue.\"\n",
    "            \" Any values in the question/response sections of the body must\"\n",
    "            \" only be based on content from the question or response, respectively.\"\n",
    "            \" Strictly adhere to all enums in the API's schema.\"\n",
    "            # We will update the following:\n",
    "            \" \\nBefore responding, think step-by-step about which of the valid\"\n",
    "            \" enums or other values best corespond to the dialog above. \"\n",
    "            \"Then, submit your ticket as a json markdown blob:\\n\"\n",
    "            '```json\\n{{\"{function_call}\": ...}}\\n```',\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_4 = llama_prompt_4.partial(\n",
    "    schema=task.schema.schema_json(), function_call=task.schema.schema()[\"title\"]\n",
    ")\n",
    "\n",
    "fireworks_extraction_chain_4 = create_extraction_chain(prompt_4)\n",
    "\n",
    "result = fireworks_extraction_chain_4.invoke(\n",
    "    {\n",
    "        \"question\": \"How do I do hybrid search?\",\n",
    "        \"answer\": \"You can one of the compatible LangChain vectorstores \"\n",
    "        \"(from langchain.vectorstores import ...) and add a filter parameter.\",\n",
    "    }\n",
    ")\n",
    "task.schema.parse_obj(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e71cd81f-0b6a-4aa7-9003-54377dab1c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama-v2-34b-code-instruct-d3a3-v2' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6/compare?selectedSessions=f085918d-085e-41f1-8ce1-b80382a1d291\n",
      "\n",
      "View all tests for Dataset Chat Extraction at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6\n",
      "[------------------------------------------------->] 27/27"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.json_edit_distance</th>\n",
       "      <th>feedback.json_schema</th>\n",
       "      <th>feedback.toxicity_similarity</th>\n",
       "      <th>feedback.sentiment_similarity</th>\n",
       "      <th>feedback.confidence_level_similarity</th>\n",
       "      <th>feedback.question_category</th>\n",
       "      <th>feedback.off_topic_similarity</th>\n",
       "      <th>feedback.programming_language_similarity</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.421309</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.970370</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.277225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.158767</td>\n",
       "      <td>0.362014</td>\n",
       "      <td>0.395847</td>\n",
       "      <td>0.181007</td>\n",
       "      <td>0.072403</td>\n",
       "      <td>0.192450</td>\n",
       "      <td>0.362014</td>\n",
       "      <td>0.506370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.928841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.094092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.319379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.314621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.939593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.388336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.654656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.533054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.208539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.733925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.533974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.json_edit_distance  feedback.json_schema  \\\n",
       "count                     27.000000             27.000000   \n",
       "unique                          NaN                   NaN   \n",
       "top                             NaN                   NaN   \n",
       "freq                            NaN                   NaN   \n",
       "mean                       0.421309              0.851852   \n",
       "std                        0.158767              0.362014   \n",
       "min                        0.094092              0.000000   \n",
       "25%                        0.314621              1.000000   \n",
       "50%                        0.388336              1.000000   \n",
       "75%                        0.533054              1.000000   \n",
       "max                        0.733925              1.000000   \n",
       "\n",
       "        feedback.toxicity_similarity  feedback.sentiment_similarity  \\\n",
       "count                      27.000000                      27.000000   \n",
       "unique                           NaN                            NaN   \n",
       "top                              NaN                            NaN   \n",
       "freq                             NaN                            NaN   \n",
       "mean                        0.814815                       0.574074   \n",
       "std                         0.395847                       0.181007   \n",
       "min                         0.000000                       0.500000   \n",
       "25%                         1.000000                       0.500000   \n",
       "50%                         1.000000                       0.500000   \n",
       "75%                         1.000000                       0.500000   \n",
       "max                         1.000000                       1.000000   \n",
       "\n",
       "        feedback.confidence_level_similarity  feedback.question_category  \\\n",
       "count                              27.000000                   27.000000   \n",
       "unique                                   NaN                         NaN   \n",
       "top                                      NaN                         NaN   \n",
       "freq                                     NaN                         NaN   \n",
       "mean                                0.970370                    0.037037   \n",
       "std                                 0.072403                    0.192450   \n",
       "min                                 0.800000                    0.000000   \n",
       "25%                                 1.000000                    0.000000   \n",
       "50%                                 1.000000                    0.000000   \n",
       "75%                                 1.000000                    0.000000   \n",
       "max                                 1.000000                    1.000000   \n",
       "\n",
       "        feedback.off_topic_similarity  \\\n",
       "count                       27.000000   \n",
       "unique                            NaN   \n",
       "top                               NaN   \n",
       "freq                              NaN   \n",
       "mean                         0.851852   \n",
       "std                          0.362014   \n",
       "min                          0.000000   \n",
       "25%                          1.000000   \n",
       "50%                          1.000000   \n",
       "75%                          1.000000   \n",
       "max                          1.000000   \n",
       "\n",
       "        feedback.programming_language_similarity error  execution_time  \n",
       "count                                  27.000000     0       27.000000  \n",
       "unique                                       NaN     0             NaN  \n",
       "top                                          NaN   NaN             NaN  \n",
       "freq                                         NaN   NaN             NaN  \n",
       "mean                                    0.444444   NaN        7.277225  \n",
       "std                                     0.506370   NaN        1.928841  \n",
       "min                                     0.000000   NaN        4.319379  \n",
       "25%                                     0.000000   NaN        5.939593  \n",
       "50%                                     0.000000   NaN        6.654656  \n",
       "75%                                     1.000000   NaN        8.208539  \n",
       "max                                     1.000000   NaN       12.533974  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_v2_CoT_test_run = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=fireworks_extraction_chain_4,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    project_name=f\"llama-v2-34b-code-instruct-{uuid.uuid4().hex[:4]}-v3\",\n",
    "    project_metadata={\"arch\": \"CoT\", \"model\": \"llama-v2-34b-code-instruct\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a1134d-54c7-4e77-8ae3-76385e0131a3",
   "metadata": {},
   "source": [
    "#### Round 5: Use Function Calling\n",
    "\n",
    "It's pretty clear that the prompting techniques aren't working. Let's try proper structure-d decoding. There are \n",
    "\n",
    "We will use Replicate's llama-2 instance, which uses Llama.cpp in the background. \n",
    "\n",
    "It can't handle all the json schema syntax, so we'll have to coerce it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93f83f13-5fbc-4464-954b-f0d52c4aba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# They don't support the #ref/ syntax\n",
    "def dereference_schema(schema, root_schema=None):\n",
    "    if root_schema is None:\n",
    "        root_schema = schema\n",
    "\n",
    "    if isinstance(schema, dict):\n",
    "        if \"$ref\" in schema:\n",
    "            ref_path = schema[\"$ref\"].split(\"/\")[1:]  # assuming '#/definitions/...'\n",
    "            ref_schema = root_schema\n",
    "            for part in ref_path:\n",
    "                ref_schema = ref_schema[part]\n",
    "            return dereference_schema(ref_schema, root_schema)\n",
    "        else:\n",
    "            return {k: dereference_schema(v, root_schema) for k, v in schema.items()}\n",
    "\n",
    "    elif isinstance(schema, list):\n",
    "        return [dereference_schema(item, root_schema) for item in schema]\n",
    "\n",
    "    return schema\n",
    "\n",
    "\n",
    "json_schema = dereference_schema(task.schema.schema())\n",
    "\n",
    "# They don't handle allOfs...\n",
    "schema_str = json.dumps(json_schema).replace(\"allOf\", \"anyOf\")\n",
    "\n",
    "# Their conversion strict doesn't properly handle exclusive maximums...\n",
    "# (it treats as inclusive)\n",
    "schema_str = re.sub(\n",
    "    r'(\"exclusiveMaximum\": )(\\d+)',\n",
    "    lambda m: f\"{m.group(1)}{int(m.group(2))-1}\",\n",
    "    schema_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f29bfab5-7f9b-47cb-8b87-68b6b199e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'issue_summary': 'Question about Retrieval Augmented Generation', 'question': {'category_if_other': 'Other', 'is_off_topic': False, 'programming_language': 'python', 'question_category': 'Concept Explanations', 'sentiment': 'Neutral', 'toxicity': 0}, 'response': {'confidence_level': 5, 'followup_actions': ['None'], 'response_type': 'provide guidance', 'response_type_if_other': 'Other'}}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Replicate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "\n",
    "model = \"andreasjansson/llama-2-70b-chat-gguf:51b87745820e6a8de6ad7bceb340bb6ba85f7ba6dab8e02bb7e2de0853425f4c\"\n",
    "\n",
    "llm = Replicate(model=model).bind(\n",
    "    jsonschema=schema_str,\n",
    ")\n",
    "\n",
    "llama_prompt = PromptTemplate.from_template(\n",
    "    \"You are a data extraction bot tasked with extracting and\"\n",
    "    \" inferring information from dialogues and generating tickets. Always respond \"\n",
    "    # For llama-2-70b-chat-gguf's API, {{jsonschema}} is a special placeholder\n",
    "    \"JSON schema:\\n{{jsonschema}}\\n\\n\"\n",
    "    \"Generate a ticket from the following question-response pair:\\n\"\n",
    "    \"<Dialogue>\\n{dialogue}\\n</Dialogue>\"\n",
    ")\n",
    "\n",
    "\n",
    "def parse(json_response: str):\n",
    "    return {\"output\": parse_json_markdown(json_response)}\n",
    "\n",
    "\n",
    "llama_gguf_chain = format_run | llama_prompt | llm | parse\n",
    "response = llama_gguf_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"What's rag about anyway?\",\n",
    "        \"answer\": \"It's retrieval augmented generation\",\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2dd7be0-6842-4dd7-bf66-e824bdee2999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'llama-gguf-1f95-v2' at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6/compare?selectedSessions=d522dbfc-c09b-45a9-b11e-26aa95a3555a\n",
      "\n",
      "View all tests for Dataset Chat Extraction at:\n",
      "https://smith.langchain.com/o/ebbaf2eb-769b-4505-aca2-d11de10372a4/datasets/08042749-504d-4509-9549-5f5c579115f6\n",
      "[------------------------------------------------->] 27/27"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.json_edit_distance</th>\n",
       "      <th>feedback.json_schema</th>\n",
       "      <th>feedback.toxicity_similarity</th>\n",
       "      <th>feedback.sentiment_similarity</th>\n",
       "      <th>feedback.confidence_level_similarity</th>\n",
       "      <th>feedback.question_category</th>\n",
       "      <th>feedback.off_topic_similarity</th>\n",
       "      <th>feedback.programming_language_similarity</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.440291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.566379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.101551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.446576</td>\n",
       "      <td>0.320256</td>\n",
       "      <td>0.492103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.576433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.280000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.412226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.374280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.851318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.435616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.641730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.523339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.656607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.642218</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.246481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.json_edit_distance  feedback.json_schema  \\\n",
       "count                     27.000000                  27.0   \n",
       "unique                          NaN                   NaN   \n",
       "top                             NaN                   NaN   \n",
       "freq                            NaN                   NaN   \n",
       "mean                       0.440291                   1.0   \n",
       "std                        0.101551                   0.0   \n",
       "min                        0.280000                   1.0   \n",
       "25%                        0.374280                   1.0   \n",
       "50%                        0.435616                   1.0   \n",
       "75%                        0.523339                   1.0   \n",
       "max                        0.642218                   1.0   \n",
       "\n",
       "        feedback.toxicity_similarity  feedback.sentiment_similarity  \\\n",
       "count                           27.0                           27.0   \n",
       "unique                           NaN                            NaN   \n",
       "top                              NaN                            NaN   \n",
       "freq                             NaN                            NaN   \n",
       "mean                             1.0                            1.0   \n",
       "std                              0.0                            0.0   \n",
       "min                              1.0                            1.0   \n",
       "25%                              1.0                            1.0   \n",
       "50%                              1.0                            1.0   \n",
       "75%                              1.0                            1.0   \n",
       "max                              1.0                            1.0   \n",
       "\n",
       "        feedback.confidence_level_similarity  feedback.question_category  \\\n",
       "count                              27.000000                   27.000000   \n",
       "unique                                   NaN                         NaN   \n",
       "top                                      NaN                         NaN   \n",
       "freq                                     NaN                         NaN   \n",
       "mean                                0.925926                    0.259259   \n",
       "std                                 0.148305                    0.446576   \n",
       "min                                 0.400000                    0.000000   \n",
       "25%                                 0.900000                    0.000000   \n",
       "50%                                 1.000000                    0.000000   \n",
       "75%                                 1.000000                    0.500000   \n",
       "max                                 1.000000                    1.000000   \n",
       "\n",
       "        feedback.off_topic_similarity  \\\n",
       "count                       27.000000   \n",
       "unique                            NaN   \n",
       "top                               NaN   \n",
       "freq                              NaN   \n",
       "mean                         0.888889   \n",
       "std                          0.320256   \n",
       "min                          0.000000   \n",
       "25%                          1.000000   \n",
       "50%                          1.000000   \n",
       "75%                          1.000000   \n",
       "max                          1.000000   \n",
       "\n",
       "        feedback.programming_language_similarity error  execution_time  \n",
       "count                                  27.000000     0       27.000000  \n",
       "unique                                       NaN     0             NaN  \n",
       "top                                          NaN   NaN             NaN  \n",
       "freq                                         NaN   NaN             NaN  \n",
       "mean                                    0.370370   NaN       55.566379  \n",
       "std                                     0.492103   NaN       24.576433  \n",
       "min                                     0.000000   NaN       16.412226  \n",
       "25%                                     0.000000   NaN       29.851318  \n",
       "50%                                     0.000000   NaN       64.641730  \n",
       "75%                                     1.000000   NaN       76.656607  \n",
       "max                                     1.000000   NaN       85.246481  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llama_v2_structured_test_run = client.run_on_dataset(\n",
    "    dataset_name=task.name,\n",
    "    llm_or_chain_factory=llama_gguf_chain,\n",
    "    evaluation=eval_config,\n",
    "    verbose=True,\n",
    "    project_name=f\"llama-gguf-{uuid.uuid4().hex[:4]}-v2\",\n",
    "    project_metadata={\n",
    "        \"arch\": \"structured-decoding\",\n",
    "        \"model\": \"llama-2-70b-chat-gguf\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aa14b9-6579-40a5-b47f-63f78cec5144",
   "metadata": {},
   "source": [
    "This gets perfect JSON results, as expected! Since the model is larger, it also does a decent job at understanding the instructions for things like the sentiment and question category.\n",
    "\n",
    "It still has room for improvement in the other classifiers: the question categorization is bad, for instance. We could try combining with  other techniques now that we are able to reliably generate in the proper structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dceef5-3a6b-434d-acdf-7a9729f36395",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "While we haven't explored a number of other prompting techniques (self-critique, output-fixing parser, etc.) and haven't given in to completely subdividing the problem (having a separate LLM call for each value and re-assembling in code), we've shown that simply applying some basic prompting techniques to a weaker base model isn't a panacea.\n",
    "\n",
    "Structured-decoding is extremely useful if you need to target a specific format or API,\n",
    "but this too only solves \"syntax\" issues without fully calibrating the correctness of the values it generates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
